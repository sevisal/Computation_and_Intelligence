---
title: "Sesi√≥n de laboratorio 3: Problemas de Regresi√≥n"
format:
    html:
        toc: true
        toc-depth: 5
        toc-location: left
        toc-title: "**Contenido**"
---

# Objetivos de la sesi√≥n

::: {.objective-card}
üéØ **Objetivo general:** Entender el modelado de regresi√≥n para que podamos construir predictores que generalicen bien y produzcan estimaciones fiables e interpretables.
:::

![](_resources/images/Regression.jpg){.img-right}
En problemas aplicados, la calidad de un modelo de regresi√≥n depende no solo del algoritmo, sino de c√≥mo planteamos el problema, preparamos las entradas y evaluamos los resultados. Incluso un modelo lineal simple puede fallar estrepitosamente si los predictores est√°n en escalas muy diferentes, si algunas variables son colineales o si puntos influyentes dominan el ajuste. El preprocesamiento para regresi√≥n, por tanto, incluye los pasos habituales de limpieza y escalado, adem√°s de un an√°lisis diagn√≥stico de los supuestos del modelo (linealidad, homocedasticidad, independencia de los errores) y de la influencia de valores at√≠picos y puntos con alto apalancamiento.

Esta sesi√≥n desarrollar√° una intuici√≥n sobre estos problemas y mostrar√° c√≥mo afectan tanto a la predicci√≥n como a la interpretaci√≥n. Examinaremos el comportamiento de los m√≠nimos cuadrados ordinarios, aprenderemos por qu√© y cu√°ndo la regularizaci√≥n (Ridge y LASSO) es √∫til, y practicaremos la selecci√≥n de hiperpar√°metros mediante validaci√≥n cruzada. Tambi√©n aprender√°s qu√© m√©tricas son apropiadas para diferentes objetivos (precisi√≥n de predicci√≥n vs. robustez vs. interpretabilidad) y c√≥mo comparar modelos sin procesar, de referencia y regularizados en datos reservados.

Dominar estas ideas te ayudar√° a evitar errores comunes ‚Äîsobreajuste, fuga de datos (data leakage), valores de R^2 enga√±osos, manejo deficiente de la multicolinealidad y estimaciones de coeficientes con exceso de confianza‚Äî, de modo que tus an√°lisis de regresi√≥n sean precisos y fiables.

---

# Actividades propuestas

A lo largo de estas actividades trabajar√°s con el conjunto de datos **California Housing**. Este conjunto contiene informaci√≥n sobre los valores de las viviendas en distritos de California durante el censo de 1990, e incluye atributos demogr√°ficos y geogr√°ficos como ingreso medio, n√∫mero medio de habitaciones y densidad de poblaci√≥n. Es un conjunto de referencia para tareas de regresi√≥n, donde el objetivo es predecir el **valor medio de la vivienda** a partir de las dem√°s variables.

![](_resources/images/Housing.jpeg){.img-center}

Puedes descargar el conjunto en formato CSV desde este enlace: https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.csv (si lo abres en el navegador, haz clic derecho y selecciona "Guardar como..." para descargarlo). Una explicaci√≥n de cada atributo est√° disponible en la documentaci√≥n de scikit-learn: https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset.

Carga el conjunto de datos en Orange y selecciona la variable objetivo para nuestro problema (`median_house_value`). Una vez que est√© disponible en tu flujo de trabajo, la usaremos para explorar el comportamiento de la regresi√≥n lineal, estudiar los riesgos del sobreajuste y entender c√≥mo las **t√©cnicas de regularizaci√≥n** y la **validaci√≥n cruzada** pueden mejorar el rendimiento del modelo. Como aprendimos la semana pasada, es crucial dividir los datos en conjuntos de entrenamiento y prueba para evaluar el rendimiento en datos no vistos.

## 1. Regresi√≥n lineal

::: {.objective-card}
üéØ **Objetivo:** Ajustar e interpretar un modelo de regresi√≥n lineal, y comprender sus supuestos y limitaciones.
:::

![](_resources/images/LR.jpg){.img-right}
La regresi√≥n lineal es el enfoque m√°s sencillo para modelar resultados continuos. Asume una relaci√≥n lineal entre los predictores (features) y la variable objetivo. Aunque es f√°cil de ajustar e interpretar, su fiabilidad depende de cu√°nto cumplan los datos ciertos supuestos: linealidad, independencia de los errores, homocedasticidad (varianza constante) y ausencia de multicolinealidad fuerte entre los predictores.

La idea de la regresi√≥n lineal es encontrar los coeficientes (pesos) para cada predictor que minimicen la suma de los cuadrados de las diferencias entre los valores observados y los predichos. Esto se conoce como el m√©todo de **M√≠nimos Cuadrados Ordinarios (OLS)** y tiene la siguiente formulaci√≥n matem√°tica:
$$
\min_{\mathbf{w}} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$
donde $y_i$ es el valor real, $\hat{y}_i$ es el valor predicho, $\mathbf{w}$ es el vector de coeficientes y $\mathbf{x}_i$ es el vector de caracter√≠sticas para la observaci√≥n $i$.

En Orange, puedes usar el widget `Linear Regression` para construir un modelo que prediga el valor de las viviendas a partir de los atributos de entrada. El widget tambi√©n permite inspeccionar los coeficientes de cada predictor haciendo clic en la parte inferior de la ventana; estos indican el cambio estimado en la variable objetivo por un cambio de una unidad en la caracter√≠stica (manteniendo las dem√°s constantes). Para observar mejor los coeficientes puedes usar el widget `Bar Plot` para visualizarlos.

Recuerda que coeficientes grandes pueden ser una se√±al de multicolinealidad o sobreajuste.

Repite el proceso usando el widget `Continuize` para estandarizar las caracter√≠sticas antes de ajustar el modelo. ¬øObservas cambios en los coeficientes?

::: {.question-card}
üìù **Preguntas:**   

1. ¬øQu√© variables parecen tener el efecto m√°s fuerte sobre los precios de la vivienda seg√∫n los coeficientes de regresi√≥n?
2. ¬øPodemos usar estos coeficientes para evaluar la importancia de las variables? ¬øPor qu√© s√≠ o por qu√© no?
3. ¬øObservas coeficientes inusualmente grandes o inestables? ¬øQu√© podr√≠a indicar esto?
:::

<!-- Solution 3. 
1. Median income is usually the strongest predictor, followed by average number of rooms. 
2. Only if the features are on the same scale and there is no multicollinearity. Standardizing helps with this.
3. Yes, some variables show large coefficients, which may indicate multicollinearity or poor scaling. 
-->

---

## 2. Evaluaci√≥n del rendimiento del modelo

::: {.objective-card}
üéØ **Objetivo:** Entender las distintas m√©tricas para evaluar el rendimiento de un modelo.
:::

![](_resources/images/performance.gif){.img-right}
Al evaluar un modelo de regresi√≥n, es crucial medir su desempe√±o en datos no vistos para asegurar que generalice bien. Normalmente se divide el conjunto en entrenamiento y prueba: el primero se usa para ajustar el modelo y el segundo para evaluarlo.

En Orange puedes usar el widget `Predictions` para evaluar el rendimiento de tu modelo de regresi√≥n. Este widget ofrece varias m√©tricas, entre ellas:

- **Error cuadr√°tico medio (MSE):** El promedio de los cuadrados de las diferencias entre los valores predichos y los reales. Penaliza m√°s los errores grandes que el MAE, por lo que es sensible a valores at√≠picos. Se calcula como:
$$
MSE = \frac{1}{N} \sum_{n=1}^{N} (y_n - \hat{y}_n)^2
$$
donde $y_n$ es el valor real, $\hat{y}_n$ es el valor predicho y $N$ es el n√∫mero de observaciones.
- **Ra√≠z del error cuadr√°tico medio (RMSE):** La ra√≠z cuadrada del MSE, proporcionando una m√©trica de error en las mismas unidades de la variable objetivo. Se calcula como:
$$
RMSE = \sqrt{MSE} = \sqrt{\frac{1}{N} \sum_{n=1}^{N} (y_n - \hat{y}_n)^2}
$$
- **Error absoluto medio (MAE):** El promedio de las diferencias absolutas entre los valores predichos y los reales. Da una idea de cu√°nto se desv√≠an las predicciones, en promedio. Se calcula como:
$$
MAE = \frac{1}{N} \sum_{n=1}^{N} |y_n - \hat{y}_n|
$$

- **Error porcentual absoluto medio (MAPE):** El promedio del porcentaje absoluto de la diferencia entre predicci√≥n y realidad. Es √∫til para entender el error en t√©rminos relativos, especialmente cuando la variable objetivo tiene un rango amplio. Se calcula como:
$$
MAPE = \frac{100\%}{N} \sum_{n=1}^{N} \left| \frac{y_n - \hat{y}_n}{y_n} \right|
$$
- **R-cuadrado ($R^2$):** La proporci√≥n de la varianza de la variable objetivo que es explicada por el modelo. Var√≠a entre 0 y 1 (aunque puede ser negativo para modelos muy malos), siendo valores m√°s altos indicativos de mejor ajuste. Se calcula como:
$$
R^2 = 1 - \frac{\sum_{n=1}^{N} (y_n - \hat{y}_n)^2}{\sum_{n=1}^{N} (y_n - \bar{y})^2}
$$
donde $\bar{y}$ es la media de los valores reales.

Usa el widget `Predictions` para evaluar tu modelo de regresi√≥n lineal sobre el conjunto de prueba. Conecta la salida del widget `Linear Regression` al widget `Predictions`, y conecta tambi√©n la salida del `Data Sampler` (conjunto de prueba) al `Predictions`. Explora las diferentes m√©tricas que proporciona el widget `Predictions`. Compara los resultados con y sin estandarizar las caracter√≠sticas usando el widget `Continuize`.

Traza los valores predichos frente a los reales con el widget `Scatter Plot` para visualizar el rendimiento del modelo. Puedes activar la opci√≥n "Show regression line" en el `Scatter Plot` para ver qu√© tan bien se alinean las predicciones con los valores reales.

::: {.question-card}
üìù **Preguntas:**

1. ¬øQu√© m√©trica de evaluaci√≥n crees que es m√°s apropiada para este problema de regresi√≥n? ¬øPor qu√©?
2. ¬øC√≥mo afecta la estandarizaci√≥n de las caracter√≠sticas al rendimiento del modelo?
3. Seg√∫n el diagrama de dispersi√≥n, ¬øqu√© tan bien captura el modelo la relaci√≥n entre las caracter√≠sticas y la variable objetivo?
:::

<!-- Soluci√≥n
1. RMSE suele preferirse porque entrega el error en las mismas unidades que la variable objetivo y penaliza m√°s los errores grandes que el MAE.
2. En teor√≠a, la regresi√≥n lineal no es sensible al escalado de las caracter√≠sticas en cuanto a predicci√≥n; sin embargo, la estandarizaci√≥n puede mejorar la estabilidad num√©rica y hacer m√°s interpretable los coeficientes.
3. El diagrama de dispersi√≥n deber√≠a mostrar una relaci√≥n cercana a la diagonal si el modelo captura bien la relaci√≥n, aunque pueden observarse desviaciones especialmente en valores extremos.
-->

---

## 3. Regularizaci√≥n 

::: {.objective-card}
üéØ **Objetivo:** Explorar los efectos de las t√©cnicas de regularizaci√≥n en el rendimiento del modelo y la diferencia entre $\ell_1$ y $\ell_2$.
:::

![](_resources/images/generalisation.jpg){.img-right}
Hemos visto que la regresi√≥n lineal puede ser sensible a la multicolinealidad y al sobreajuste, especialmente cuando hay muchos predictores. Las t√©cnicas de regularizaci√≥n, como Ridge (regularizaci√≥n $\ell_2$) y LASSO (regularizaci√≥n $\ell_1$), ayudan a mitigar estos problemas a√±adiendo un t√©rmino de penalizaci√≥n a la funci√≥n de p√©rdida. Esto incentiva modelos m√°s simples que generalizan mejor a datos no vistos.

En Ridge, el t√©rmino de penalizaci√≥n es la suma de los cuadrados de los coeficientes, mientras que en LASSO es la suma de los valores absolutos de los coeficientes. Las formulaciones matem√°ticas son:

- **Ridge Regression:**
$$
L_{Ridge}(\mathbf{w}) = \sum_{i=1}^{N} (y_i - \hat{y}_i)^2 + \lambda \sum_{j=1}^{M} w_j^2
$$
- **LASSO Regression:**
$$
L_{LASSO}(\mathbf{w}) = \sum_{i=1}^{N} (y_i - \hat{y}_i)^2 + \lambda \sum_{j=1}^{M} |w_j|
$$

donde $\lambda$ es el par√°metro de regularizaci√≥n que controla la intensidad de la penalizaci√≥n, $M$ es el n√∫mero de predictores y $w_j$ son los coeficientes.

En Orange puedes usar las opciones `Ridge Regression` y `Lasso Regression` en el widget `Linear Regression` para ajustar modelos con estas t√©cnicas. Experimenta con diferentes valores del par√°metro de regularizaci√≥n $\lambda$ (a menudo llamado alpha en los widgets) para ver c√≥mo afectan a los coeficientes y al rendimiento del modelo.

### 3.1. Regularizaci√≥n frente al sobreajuste

![](_resources/images/copy.gif){.img-right}
Para ilustrar los efectos de la regularizaci√≥n, crearemos un conjunto de datos sint√©tico con caracter√≠sticas repetidas que pueden inducir sobreajuste. Puedes descargar el conjunto con caracter√≠sticas repetidas de `MedInc` en el siguiente enlace: [Descargar conjunto con caracter√≠sticas redundantes](https://github.com/sevisal/Computation_and_Intelligence/raw/main/_resources/data/california_housing_data_rep.csv).

Carga el conjunto en Orange y ajusta un modelo de regresi√≥n lineal sin regularizaci√≥n. Observa los coeficientes y el rendimiento del modelo en el conjunto de prueba usando el widget `Test & Score`. Luego ajusta modelos Ridge y LASSO con distintos valores de $\lambda$ y compara sus coeficientes y rendimiento.

::: {.question-card}
üìù **Preguntas:**

1. ¬øC√≥mo cambian los coeficientes con distintos valores de $\lambda$ para Ridge y LASSO?
2. ¬øQu√© t√©cnica de regularizaci√≥n parece funcionar mejor en este escenario? ¬øPor qu√©?
3. ¬øC√≥mo ayuda la regularizaci√≥n a mitigar el sobreajuste en este caso?
:::

<!-- Soluci√≥n
1. A medida que $\lambda$ aumenta, los coeficientes en Ridge y LASSO tienden a reducirse hacia cero. LASSO puede llevar algunos coeficientes exactamente a cero, realizando selecci√≥n de variables.
2. LASSO puede funcionar mejor en este escenario porque puede eliminar caracter√≠sticas redundantes poniendo sus coeficientes a cero, produciendo un modelo m√°s simple.
3. La regularizaci√≥n penaliza coeficientes grandes, desalentando que el modelo ajuste ruido en los datos de entrenamiento y mejorando la generalizaci√≥n a datos no vistos.
-->

### 3.2. Validaci√≥n cruzada para sintonizar hiperpar√°metros

::: {.objective-card}
üéØ **Objetivo:** Usar validaci√≥n cruzada para seleccionar el par√°metro de regularizaci√≥n $\lambda$ √≥ptimo para Ridge y LASSO.
:::

En esta secci√≥n trabajaremos con un escenario de alta dimensionalidad con caracter√≠sticas polinomiales. Puedes descargar el conjunto con caracter√≠sticas polinomiales desde: [Descargar conjunto polinomial](https://github.com/sevisal/Computation_and_Intelligence/raw/main/_resources/data/california_housing_data_poly.csv).

Elegir el valor correcto de $\lambda$ es crucial para balancear sesgo y varianza. Un enfoque com√∫n es usar validaci√≥n cruzada: particionar los datos de entrenamiento en varios pliegues, entrenar el modelo en algunos pliegues y validar en el resto, repitiendo esto para distintos valores de $\lambda$ y seleccionando el que minimice el error medio en las validaciones.

![](_resources/images/crowded.gif){.img-right}
En Orange puedes usar el widget `Test & Score` con validaci√≥n cruzada para evaluar el rendimiento de Ridge y LASSO con distintos valores de $\lambda. Orange no dispone de un sintonizador de hiperpar√°metros autom√°tico, por lo que deber√°s crear un widget `Linear Regression` por cada valor de $\lambda y conectarlos al `Test & Score`. Aseg√∫rate de incluir el widget de `Preprocessing` con la opci√≥n `Standardize` y pasarlo tambi√©n al `Test & Score` para que la estandarizaci√≥n se haga dentro de cada pliegue y evitar fuga de datos.

Encuentra el valor √≥ptimo de $\lambda$ para Ridge y LASSO comparando su rendimiento en los pliegues de validaci√≥n. Una vez seleccionado el mejor $\lambda$, ajusta el modelo final con el conjunto de entrenamiento completo y eval√∫a su rendimiento en el conjunto de prueba.

::: {.question-card}
üìù **Preguntas:**

1. ¬øCu√°l es el valor √≥ptimo de $\lambda$ para Ridge y LASSO seg√∫n la validaci√≥n cruzada?
2. ¬øC√≥mo compara el rendimiento de los modelos finales con el modelo de regresi√≥n lineal sin regularizaci√≥n?
3. ¬øC√≥mo ayuda la validaci√≥n cruzada a seleccionar el par√°metro de regularizaci√≥n y mejorar la generalizaci√≥n del modelo?
:::

<!-- Soluci√≥n
1. El valor √≥ptimo de $\lambda$ depende del conjunto de datos y los resultados de la validaci√≥n cruzada; t√≠picamente es el que minimiza el error medio de validaci√≥n.
2. Los modelos finales con regularizaci√≥n deber√≠an tener mejor rendimiento en el conjunto de prueba que el modelo sin regularizaci√≥n, al reducir el sobreajuste.
3. La validaci√≥n cruzada proporciona una estimaci√≥n m√°s robusta del rendimiento al evaluar el modelo en m√∫ltiples particiones, ayudando a elegir un $\lambda$ que generalice bien.
-->

---

# Mini-proyecto: Problemas de regresi√≥n y regularizaci√≥n

En este mini-proyecto aplicar√°s lo aprendido sobre preprocesamiento y regularizaci√≥n en regresi√≥n.

![](_resources/images/energy.jpg){.img-right}

Imagina que te unes a una iniciativa de investigaci√≥n sobre arquitectura sostenible. El equipo trabaja con el conjunto de datos **Energy Efficiency** (disponible en el siguiente enlace: https://www.kaggle.com/datasets/elikplim/eergy-efficiency-dataset/download). Contiene par√°metros de edificios como √°rea de muros, √°rea de techo y √°rea de acristalamiento, junto con dos variables objetivo: la carga de calefacci√≥n y la carga de refrigeraci√≥n requerida para cada dise√±o. Para este ejercicio, debes **elegir una de las dos variables objetivo** para predecir. Parte de tu tarea es justificar por qu√© seleccionaste esa variable y c√≥mo afecta tus decisiones de modelado.

El conjunto plantea varios retos √∫tiles: varias variables est√°n en escalas distintas, lo que puede distorsionar la influencia de los predictores si no se ajusta; adem√°s hay fuertes correlaciones entre entradas que pueden producir inestabilidad en modelos lineales. Estos problemas subrayan la importancia del preprocesamiento y la regularizaci√≥n.

Tu tarea es dise√±ar un flujo de trabajo en Orange que prepare este conjunto para modelado y luego construya un modelo de regresi√≥n lineal regularizado. Esto incluir√° decisiones sobre transformaciones, si normalizar o estandarizar variables y c√≥mo manejar predictores correlacionados. Despu√©s de preparar los datos, entrenar√°s un modelo con regularizaci√≥n, validar√°s la elecci√≥n del par√°metro de regularizaci√≥n mediante validaci√≥n cruzada y finalmente evaluar√°s su rendimiento en un conjunto de prueba reservado.

No hay una √∫nica soluci√≥n correcta. Lo importante es que puedas explicar y justificar tus decisiones. Al final, guarda tu flujo de trabajo y escribe una breve reflexi√≥n describiendo c√≥mo preparaste los datos, qu√© pasos consideraste innecesarios, qu√© objetivo elegiste para predecir y c√≥mo afect√≥ la regularizaci√≥n al rendimiento del modelo final.

# Nota final

::: {.final-note-card}
‚ú® ¬°Felicidades por completar el Laboratorio 3! Has explorado los fundamentos del an√°lisis de regresi√≥n, incluyendo ajuste de modelos lineales, evaluaci√≥n de su rendimiento y aplicaci√≥n de regularizaci√≥n para mejorar la generalizaci√≥n.

En la pr√≥xima sesi√≥n profundizar√°s en problemas de clasificaci√≥n, aprendiendo a construir modelos que categorizan datos en clases distintas. Veremos diferentes algoritmos, m√©tricas de rendimiento y estrategias para manejar conjuntos desbalanceados. ¬°Disfruta el viaje en el mundo del aprendizaje autom√°tico! üöÄ
:::

::: {.margin}
# Explora los Laboratorios {.unnumbered .unlisted}
{{< include lab-cards.es.qmd >}}
:::