---
title: "Sesi√≥n de laboratorio 4: Problemas de Clasificaci√≥n"
format:
    html:
        toc: true
        toc-depth: 5
        toc-location: left
        toc-title: "**Contents**"
---

# Objetivos de la sesi√≥n

::: {.objective-card}
üéØ **Objetivo general:** Aprender a plantear y evaluar problemas de clasificaci√≥n, desarrollando modelos que no solo alcancen buena precisi√≥n, sino que tambi√©n ofrezcan informaci√≥n sobre los patrones que separan los grupos de inter√©s.
:::

![](_resources/images/The_Square_Hole.jpg){.img-right}

La clasificaci√≥n es una de las tareas m√°s utilizadas en el aprendizaje autom√°tico, especialmente en la investigaci√≥n biom√©dica y cl√≠nica. A diferencia de la regresi√≥n, donde predecimos un resultado continuo, aqu√≠ el objetivo es asignar cada observaci√≥n a una categor√≠a discreta. Este cambio de perspectiva lo cambia todo: desde el tipo de algoritmos que utilizamos, hasta c√≥mo evaluamos el √©xito, y las consecuencias de diferentes tipos de errores. Un modelo que clasifica err√≥neamente la condici√≥n de un paciente, por ejemplo, tiene una implicaci√≥n muy diferente a la de un modelo que subestima ligeramente un biomarcador continuo.

Las buenas canalizaciones de clasificaci√≥n requieren una cuidadosa reflexi√≥n sobre el equilibrio de clases, la elecci√≥n de caracter√≠sticas y la compensaci√≥n entre sensibilidad y especificidad. Incluso los modelos altamente precisos pueden ser enga√±osos si se sobreajustan a los artefactos en los datos o si no logran generalizar m√°s all√° de la cohorte de entrenamiento. La evaluaci√≥n, por lo tanto, exige m√°s que una sola m√©trica: la precisi√≥n, la recuperaci√≥n, la puntuaci√≥n F1 y las matrices de confusi√≥n proporcionan perspectivas complementarias sobre el rendimiento. Esta sesi√≥n cultivar√° una intuici√≥n para estos problemas, mostrando c√≥mo se comportan los diferentes algoritmos en diversas condiciones y c√≥mo las estrategias de validaci√≥n adecuadas nos ayudan a juzgar la fiabilidad de nuestros resultados.

# Actividades propuestas

En esta sesi√≥n trabajaremos con el conjunto de datos **C√©lulas mononucleares de m√©dula √≥sea con AML**, disponible directamente en los conjuntos de datos de widgets de Orange. Esta colecci√≥n contiene perfiles gen√≥micos de c√©lulas individuales de m√©dula √≥sea, algunas de las cuales provienen de pacientes con **leucemia mieloide aguda (AML)** y otras de donantes sanos. La tarea es clasificar si cada c√©lula pertenece al grupo de AML o al grupo de control sano en funci√≥n de su perfil de expresi√≥n.

![](_resources/images/bone.jpg){.img-center}

Este conjunto de datos ilustra varios desaf√≠os centrales de la clasificaci√≥n biom√©dica: datos de alta dimensi√≥n, variabilidad biol√≥gica y la necesidad de reglas de decisi√≥n interpretables. Al cargarlo en Orange, seleccionar la variable objetivo correcta (tipo de c√©lula: AML vs. sano) y conectarlo con aprendices de clasificaci√≥n, explorar√°s el rendimiento de algoritmos comunes como la regresi√≥n log√≠stica y los vecinos m√°s cercanos (k-NN). Tambi√©n investigaremos c√≥mo el desequilibrio de clases afecta el comportamiento del modelo y por qu√© la validaci√≥n cruzada es esencial para obtener una estimaci√≥n justa de la precisi√≥n predictiva.

A trav√©s de estas actividades, desarrollar√°s una comprensi√≥n pr√°ctica de c√≥mo dise√±ar, entrenar y evaluar modelos de clasificaci√≥n en entornos donde tanto la precisi√≥n como la interpretabilidad son importantes.

---

## 1. Preparar los datos
::: {.objective-card}
üéØ **Objetivo:** Comprender el conjunto de datos y prepararlo para la clasificaci√≥n.
:::

En esta primera parte cargaremos el conjunto de datos y realizaremos una exploraci√≥n y preprocesamiento inicial. Esto incluye comprobar valores faltantes, entender la distribuci√≥n de las clases y visualizar los datos. Aseg√∫rate de configurar correctamente la variable objetivo para indicar si cada c√©lula proviene de un paciente con AML o de un donante sano.

Divide los datos en conjuntos de entrenamiento y prueba, manteniendo el mismo porcentaje de muestras en cada subconjunto y estratificando por la variable objetivo. Esto nos ayudar√° a evaluar el rendimiento del modelo con mayor precisi√≥n m√°s adelante. Visualiza las muestras y c√≥mo est√°n distribuidas.

::: {.question-card}
üìù **Preguntas:**  

1. ¬øCu√°ntas muestras hay en cada clase (AML vs. sano)? ¬øEst√° el conjunto de datos equilibrado o desequilibrado?
2. ¬øQu√© informaci√≥n obtuviste de la visualizaci√≥n inicial de los datos?
3. Bas√°ndote en tu exploraci√≥n, ¬øcrees que necesitamos hacer alg√∫n preprocesamiento adicional?
:::

---

## 2. M√©todos de clasificaci√≥n
::: {.objective-card}
üéØ **Objetivo:** Aprender qu√© son los m√©todos de clasificaci√≥n y qu√© informaci√≥n aprenden.
:::

Los algoritmos de clasificaci√≥n aprenden a asignar etiquetas a los puntos de datos en funci√≥n de sus caracter√≠sticas. A diferencia de la regresi√≥n, que predice resultados continuos, la clasificaci√≥n se ocupa de categor√≠as discretas. En esta parte, exploraremos dos algoritmos de clasificaci√≥n fundamentales: **regresi√≥n log√≠stica** y **k-vecinos m√°s cercanos (k-NN)**. Entrenaremos estos modelos en el conjunto de entrenamiento y evaluaremos su rendimiento en el conjunto de prueba.

### 2.1 Regresi√≥n Log√≠stica

La semana pasada vimos c√≥mo usar la regresi√≥n lineal para predecir resultados continuos. Ahora, exploraremos la **regresi√≥n log√≠stica**, que se utiliza para tareas de clasificaci√≥n. La regresi√≥n log√≠stica modela la probabilidad de un resultado binario en funci√≥n de una o m√°s variables predictoras. Si la comparamos con la regresi√≥n lineal, podemos ver que mientras la regresi√≥n lineal predice un valor continuo, la regresi√≥n log√≠stica predice la probabilidad de pertenencia a una clase (por ejemplo, la probabilidad de estar en el grupo AML). La ecuaci√≥n para la regresi√≥n log√≠stica es:
$$
P(Y=1|X) = \frac{1}{1 + e^{-(w_0 + X_1 w_1 + ... + X_n w_n)}},
$$

donde $P(Y=1|X)$ es la probabilidad de la clase positiva (por ejemplo, AML), $w_0$ es la intersecci√≥n, $X_i$ son las variables predictoras y $w_i$ son los coeficientes.

En esta parte, conectar√°s los datos de entrenamiento a un widget de **Logistic Regression** en Orange, configurar√°s sus par√°metros y entrenar√°s el modelo. Luego, conectar√°s el modelo entrenado a un widget de **Bar Plot** para visualizar los coeficientes del modelo. Esto te ayudar√° a entender qu√© caracter√≠sticas son m√°s influyentes en la predicci√≥n de la clase.

::: {.question-card}
üìù **Preguntas:**  

1. ¬øC√≥mo difiere la regresi√≥n log√≠stica de la regresi√≥n lineal?
2. ¬øCu√°les son algunas ventajas de usar la regresi√≥n log√≠stica para tareas de clasificaci√≥n?
3. ¬øC√≥mo podemos interpretar los coeficientes de un modelo de regresi√≥n log√≠stica?
:::

### 2.2 k-vecinos m√°s cercanos (k-NN)

![](_resources/images/neighbor.jpg){.img-right}
A continuaci√≥n, exploraremos el algoritmo de **k-vecinos m√°s cercanos (k-NN)**, que es un m√©todo de clasificaci√≥n sencillo pero efectivo. El algoritmo k-NN clasifica un nuevo punto de datos en funci√≥n de la clase mayoritaria de sus 'k' vecinos m√°s pr√≥ximos en el conjunto de entrenamiento. Es un m√©todo no param√©trico, lo que significa que no hace supuestos sobre la distribuci√≥n subyacente de los datos. La elecci√≥n de 'k' (el n√∫mero de vecinos a considerar) puede afectar significativamente el rendimiento del modelo. Un 'k' peque√±o puede llevar a sobreajuste, mientras que un 'k' grande puede suavizar en exceso la frontera de decisi√≥n.

Usa el widget `Scatter Plot` para visualizar c√≥mo se distribuyen los puntos de entrenamiento respecto a las variables `HBB` y `HBD`. No es necesario conectar la salida del widget de `k-NN` al Scatter Plot (ya que k-NN es no param√©trico); conecta √∫nicamente los datos de entrenamiento . Colorea los puntos seg√∫n la variable objetivo (tipo de c√©lula: AML vs. sano) para ver qu√© tan separadas est√°n las clases en este espacio 2D.

::: {.question-card}
üìù **Preguntas:**  

1. ¬øEn qu√© se diferencia k-NN de la regresi√≥n log√≠stica?  
2. ¬øCu√°les son algunas ventajas de usar k-NN para tareas de clasificaci√≥n?  
3. ¬øQu√© puedes observar sobre la distribuci√≥n de puntos en el diagrama de dispersi√≥n? ¬øC√≥mo se relaciona esto con el rendimiento del modelo k-NN?
:::

## 3. Visualizaci√≥n de fronteras de decisi√≥n
::: {.objective-card}
üéØ **Objetivo:** Entender qu√© son las fronteras de decisi√≥n y c√≥mo visualizarlas.
:::

![](_resources/images/decission.jpg){.img-right}
Las fronteras de decisi√≥n son las superficies que separan diferentes clases en el espacio de caracter√≠sticas. Representan los puntos donde el modelo no est√° seguro sobre la etiqueta de clase, lo que significa que un peque√±o cambio en las caracter√≠sticas de entrada podr√≠a llevar a una clasificaci√≥n diferente. Entender las fronteras de decisi√≥n es crucial para interpretar c√≥mo un modelo de clasificaci√≥n toma decisiones y para identificar √°reas potenciales de mala clasificaci√≥n.

Vamos a utilizar un complemento llamado **Educational** para visualizar la frontera de decisi√≥n del modelo de regresi√≥n log√≠stica. Esto nos ayudar√° a entender c√≥mo el modelo separa las dos clases en funci√≥n de las caracter√≠sticas. Para instalar el complemento, ve a **Options > Add-ons** en Orange y selecciona **Educational** de la lista. Una vez instalado, puedes encontrar el widget **Polynomial Classification** en la secci√≥n **Educational** de la caja de herramientas. Una vez que hayas entrenado los modelos de clasificaci√≥n, conecta cada uno de ellos a un widget **Polynomial Classification** junto con los datos de prueba para visualizar la frontera de decisi√≥n. Puedes configurar el widget para mostrar la frontera de decisi√≥n para diferentes pares de caracter√≠sticas, como `HBB` y `HBD`.

::: {.question-card}
üìù **Preguntas:**

1. ¬øQu√© son las fronteras de decisi√≥n y por qu√© son importantes en las tareas de clasificaci√≥n?
2. ¬øC√≥mo puede la visualizaci√≥n de las fronteras de decisi√≥n ayudarnos a entender el rendimiento del modelo?
3. ¬øQu√© desaf√≠os podr√≠an surgir al visualizar las fronteras de decisi√≥n en espacios de alta dimensi√≥n?
:::

## 4. Evaluaci√≥n del modelo
::: {.objective-card}
üéØ **Objetivo:** Aprender a evaluar modelos de clasificaci√≥n utilizando m√©tricas apropiadas.
:::

Al igual que con los modelos de regresi√≥n, evaluar los modelos de clasificaci√≥n es crucial para entender su rendimiento. Sin embargo, las m√©tricas utilizadas para la clasificaci√≥n son diferentes de las utilizadas para la regresi√≥n. En la clasificaci√≥n, utilizamos m√©tricas que consideran la naturaleza discreta de los resultados. Estas se derivan t√≠picamente de la matriz de confusi√≥n, que resume los recuentos de muestras correctamente predichas como positivas (verdaderos positivos), correctamente predichas como negativas (verdaderos negativos), incorrectamente predichas como positivas (falsos positivos) e incorrectamente predichas como negativas (falsos negativos).

Algunas m√©tricas comunes incluyen:

- **Matriz de Confusi√≥n**: Una tabla que resume el rendimiento de un modelo de clasificaci√≥n mostrando los recuentos de predicciones verdaderas positivas, verdaderas negativas, falsas positivas y falsas negativas.
- **Precisi√≥n (Accuracy)**: La proporci√≥n de instancias clasificadas correctamente sobre el total de instancias.
$$
\text{Accuracy} = \frac{\text{True Positives} + \text{True Negatives}}{\text{Total Instances}}
$$
- **Precisi√≥n (Precision)**: La proporci√≥n de predicciones verdaderas positivas sobre todas las predicciones positivas realizadas por el modelo.
$$
\text{Precision} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}
$$
- **Recall (Sensibilidad)**: La proporci√≥n de predicciones verdaderas positivas sobre todas las instancias positivas reales.
$$
\text{Recall} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}
$$
- **F1 Score**: La media arm√≥nica de la precisi√≥n y el recall, proporcionando una √∫nica m√©trica que equilibra ambas.
$$
\text{F1 Score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
$$

Para evaluar los modelos, conecta los datos de prueba y los modelos entrenados a un widget de **Predicciones** en Orange. Este widget calcular√° varias m√©tricas de evaluaci√≥n para cada modelo, lo que te permitir√° comparar su rendimiento.

Adem√°s, puedes utilizar el widget de **Confusion Matrix** para visualizar la matriz de confusi√≥n de cada modelo. Para hacer esto, primero debes conectar los datos de prueba y los modelos entrenados a un widget de **Predictions**, y luego conectar la salida del widget de **Predictions** al widget de **Confusion Matrix**.

::: {.question-card}
üìù **Preguntas:**

1. ¬øCu√°les son las principales diferencias entre las m√©tricas de evaluaci√≥n para regresi√≥n y clasificaci√≥n?
2. ¬øPor qu√© es importante considerar m√∫ltiples m√©tricas al evaluar modelos de clasificaci√≥n?
3. Basado en los resultados de la evaluaci√≥n, ¬øqu√© modelo tuvo un mejor rendimiento y por qu√©?
:::

## 5. Desbalanceo de datos
::: {.objective-card}
üéØ **Objetivo:** Aprender a manejar conjuntos de datos desbalanceados en tareas de clasificaci√≥n.
:::

![](_resources/images/balance.jpg){.img-right}
El desbalanceo de clases ocurre cuando las clases en un conjunto de datos no est√°n representadas por igual. Por ejemplo, en un conjunto de diagn√≥stico m√©dico puede haber muchos m√°s pacientes sanos que pacientes con una enfermedad espec√≠fica. Este desbalanceo puede conducir a modelos sesgados que funcionan bien en la clase mayoritaria pero mal en la clase minoritaria. Para abordar el desbalanceo de clases, podemos emplear t√©cnicas como sobremuestreo de la clase minoritaria, submuestreo de la clase mayoritaria o m√©todos de generaci√≥n sint√©tica como SMOTE (Synthetic Minority Over-sampling Technique).

Dado que este conjunto de datos est√° casi perfectamente equilibrado, simularemos un escenario desequilibrado. Para ello, conecta los datos de entrenamiento a un widget **Select Rows** en Orange. Configura el widget para usar solo las muestras con un valor de `HBG1` mayor que 0. Visualiza la distribuci√≥n de clases con un widget **Distributions** para confirmar el desbalanceo.

Despu√©s de crear el conjunto desequilibrado, reentrena los modelos de regresi√≥n log√≠stica y k-NN usando este nuevo conjunto de entrenamiento. A continuaci√≥n, eval√∫a su rendimiento en el conjunto de prueba original utilizando los widgets **Predictions** y **Confusion Matrix**. Compara los resultados con los obtenidos en el conjunto equilibrado.

::: {.question-card}
üìù **Preguntas:**

1. ¬øQu√© cambios observaste en el rendimiento del modelo tras introducir el desequilibrio de clases?  
2. ¬øC√≥mo puedes mitigar los efectos del desequilibrio en tus modelos? 
:::

<!-- Solutions:
1. The model performance likely decreased, especially in metrics like recall and F1 score for the minority class. The models may have become biased towards predicting the majority class, leading to a higher number of false negatives for the minority class.
2. To mitigate the effects of class imbalance, you can use techniques such as oversampling the minority class, undersampling the majority class, or using synthetic data generation methods like SMOTE. Additionally, you can experiment with different algorithms that are more robust to class imbalance or use ensemble methods to improve performance on the minority class.
 -->

---

# Mini-proyecto: Clasificaci√≥n con datos desbalanceados

![](_resources/images/fraud.jpg){.img-right}
En este mini-proyecto, aplicar√°s lo que has aprendido sobre clasificaci√≥n, m√©tricas de evaluaci√≥n y estrategias para manejar el desbalanceo de clases.

Imagina que est√°s colaborando con una startup fintech que desarrolla herramientas para detectar transacciones fraudulentas. El equipo te proporciona el conjunto de datos **Credit Card Fraud Detection** (disponible en el siguiente [enlace](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/download)). Contiene caracter√≠sticas anonimizadas derivadas de transacciones con tarjeta de cr√©dito realizadas en septiembre de 2013 por titulares de tarjetas europeos. Entre las 284,807 transacciones, solo 492 son fraudulentas, menos del 0.2% de los datos. La variable objetivo (`Class`) indica si una transacci√≥n es fraudulenta (1) o leg√≠tima (0).

La primera impresi√≥n nos dice que este es un problema t√≠pico de clasificaci√≥n binaria, pero el desequilibrio extremo de clases crea desaf√≠os serios. Un clasificador ingenuo que predice "leg√≠timo" para todos los casos lograr√≠a m√°s del 99% de precisi√≥n, pero ser√≠a in√∫til en la pr√°ctica. Este proyecto te ayudar√° a ver por qu√© la **precisi√≥n por s√≠ sola no es suficiente** y por qu√© m√©tricas como la precisi√≥n, el recall, la puntuaci√≥n F1 y la curva ROC son esenciales para evaluar el rendimiento en tales contextos.

Tu tarea es dise√±ar un flujo de trabajo en Orange que aborde este problema. Debes cargar y explorar el conjunto de datos, examinar la distribuci√≥n de las clases objetivo y luego construir y comparar modelos de clasificaci√≥n como regresi√≥n log√≠stica, bosques aleatorios y m√°quinas de soporte vectorial. Parte de tu trabajo ser√° considerar estrategias para abordar el desbalanceo de clases, como el re-muestreo, el ajuste de los umbrales de clasificaci√≥n o el enfoque en m√©tricas de evaluaci√≥n sensibles al costo.

Una vez que tus modelos est√©n entrenados y validados, reflexiona sobre c√≥mo el desbalanceo de clases influy√≥ en tus decisiones, qu√© m√©tricas capturaron mejor el rendimiento del modelo y si priorizar√≠as detectar tantos casos de fraude como fuera posible (alto recall) o evitar falsas alarmas (alta precisi√≥n).

Al igual que en proyectos anteriores, no hay un √∫nico flujo de trabajo correcto. Diferentes flujos de trabajo pueden dar lugar a diferentes compensaciones, y lo que m√°s importa es que puedas explicar y justificar tus elecciones de dise√±o.

# Nota final

::: {.final-note-card}
‚ú® ¬°Felicidades por completar el Laboratorio 4! Has explorado los fundamentos de los problemas de clasificaci√≥n, incluyendo el manejo de conjuntos de datos desbalanceados, la evaluaci√≥n del rendimiento del modelo y la aplicaci√≥n de diferentes algoritmos para mejorar la precisi√≥n de clasificaci√≥n.

En la pr√≥xima sesi√≥n, profundizaremos en las t√©cnicas de agrupamiento, que nos permitir√°n agrupar puntos de datos similares sin etiquetas predefinidas. Esto mejorar√° a√∫n m√°s tu comprensi√≥n de los m√©todos de aprendizaje no supervisado y sus aplicaciones en varios dominios.
:::

::: {.margin}
# Explora los Laboratorios {.unnumbered .unlisted}
{{< include lab-cards.es.qmd >}}
:::