---
title: "Sesi√≥n de laboratorio 2: Preprocesamiento de datos"
format:
    html:
        toc: true
        toc-depth: 5
        toc-location: left
        toc-title: "**Contenido**"
---

# Objetivos de la sesi√≥n

::: {.objective-card}
üéØ **Objetivo general:**  
Aprender a preparar y preprocesar datos antes de modelar, asegurando que los conjuntos de datos con los que trabajamos sean consistentes, significativos y est√©n listos para los algoritmos de aprendizaje autom√°tico.  
:::

![](_resources/images/processing.gif){.img-right}

En proyectos reales, la calidad de los datos determina en gran medida la calidad del modelo. No importa cu√°n sofisticado sea un algoritmo, si los datos de entrada son deficientes, las predicciones ser√°n poco fiables. El preprocesamiento es la etapa donde limpiamos, transformamos y estructuramos los datos para que los modelos puedan aprender de manera efectiva y sin distorsiones.

En esta sesi√≥n, desarrollaremos una comprensi√≥n de por qu√© el preprocesamiento es esencial y luego lo aplicaremos en la pr√°ctica. Ver√°s c√≥mo identificar y seleccionar atributos relevantes, tratar valores faltantes, normalizar variables que existen en escalas muy diferentes e investigar el efecto de los valores at√≠picos. Tambi√©n aprender√°s por qu√© es crucial separar los datos en subconjuntos de entrenamiento y prueba antes de la evaluaci√≥n. Finalmente, comparar√°s conjuntos de datos en bruto y preprocesados para apreciar cu√°nto pueden cambiar los resultados en la pr√°ctica. Dominar estas ideas te ayudar√° a evitar errores comunes como el data leakage, modelos sesgados o sobreajuste.

---

# Actividades propuestas

A lo largo de estas actividades, trabajar√°s con el conjunto de datos `Chronic Kidney Disease`. Este conjunto contiene informaci√≥n sobre pacientes con enfermedad renal cr√≥nica, incluyendo diversos atributos m√©dicos y demogr√°ficos. Es un benchmark com√∫n para tareas de clasificaci√≥n, donde el objetivo es predecir la presencia o ausencia de la enfermedad en funci√≥n de otras variables. Puedes descargarlo desde [este enlace](https://www.kaggle.com/datasets/mansoordaku/ckdisease/download) y puedes encontrar una explicaci√≥n de cada atributo en [UCI](https://archive.ics.uci.edu/dataset/336/chronic+kidney+disease). Carga el conjunto de datos como hicimos en la sesi√≥n anterior (usando el widget **CSV File Import**). ¬°Una vez listo, podemos comenzar a preprocesarlo!

## 1. Limpieza de datos

::: {.objective-card}
üéØ **Objetivo:** Identificar y tratar categor√≠as de texto.
:::

El primer paso en el preprocesamiento es asegurarse de que los datos sean limpios y consistentes. Esto implica identificar y tratar categor√≠as de texto, as√≠ como asegurarse de que las variables categ√≥ricas est√©n correctamente formateadas.

![](_resources/images/cleaning.jpg){.img-right}

Visualiza el contenido del conjunto de datos y encuentra cualquier error que pueda haber ocurrido durante la recopilaci√≥n. Identifica las categor√≠as de texto y busca variables que contengan datos de texto, como "yes"/"no" u otros valores categ√≥ricos, y aseg√∫rate de que los valores √∫nicos est√©n correctamente codificados. Puedes usar el widget **Edit Domain** para renombrar o recodificar estas categor√≠as si es necesario. Puede haber inconsistencias en c√≥mo se representan las categor√≠as (por ejemplo, "yes", "Yes", "YES"). Estandariza estas entradas para asegurar uniformidad.

Aseg√∫rate de que la variable correcta est√© establecida como variable objetivo (la que quieres predecir). En este caso, debe ser la variable que indica la presencia o ausencia de enfermedad renal cr√≥nica (CKD). Puedes usar el widget **Select Columns** para establecer la variable objetivo adecuadamente.

::: {.question-card}
üìù **Preguntas:**  

1. ¬øHay inconsistencias en las categor√≠as de texto? Si es as√≠, ¬øc√≥mo las estandarizaste?
2. ¬øQu√© variable estableciste como variable objetivo y por qu√©?
3. ¬øEncontraste otros problemas en el conjunto de datos que deb√≠an ser tratados? Si es as√≠, ¬øcu√°les?
:::

<!-- Soluci√≥n
1. S√≠, hab√≠a inconsistencias como "yes", "Yes" y "YES". Las estandaric√© todas a "yes" usando el widget Edit Domain.
2. Establec√≠ la variable que indica la presencia o ausencia de CKD como variable objetivo porque es el resultado que queremos predecir.
3. Encontr√© algunos valores faltantes en ciertos atributos, que tratar√© en el siguiente paso.
    -->

---

## 2. Particiones de datos

::: {.objective-card}
üéØ **Objetivo:** Comprender la importancia de realizar particiones en el conjunto de datos.  
:::

Cuando construimos un modelo de aprendizaje autom√°tico, queremos que aprenda patrones que pueda aplicar a nuevas situaciones, no solo memorizar los ejemplos que le damos. Para comprobar si esto ocurre, necesitamos separar nuestros datos en dos partes:

- **Conjunto de entrenamiento:** los datos que el modelo usa para aprender.
- **Conjunto de prueba:** los datos que reservamos para comprobar c√≥mo funciona el modelo en ejemplos no vistos.

Si solo probamos el modelo con los mismos datos con los que fue entrenado, los resultados pueden ser enga√±osos. El modelo podr√≠a parecer perfecto simplemente porque ha memorizado las respuestas, pero esto nos dice poco sobre c√≥mo se comportar√° en el mundo real.

![](_resources/images/exam.gif){.img-right}

Piensa en ello como estudiar para un examen:

- Practicas con ejercicios del libro (**entrenamiento**).
- Luego haces el examen real, que tiene preguntas diferentes (**prueba**).

Solo si te va bien en el examen puedes estar seguro de que realmente entiendes el material, en vez de solo memorizar los ejercicios de pr√°ctica. El aprendizaje autom√°tico funciona igual: probar con datos nuevos muestra si el modelo realmente ha aprendido y puede generalizar a casos futuros.

### 2.1 Particiones aleatorias

Comienza creando una partici√≥n aleatoria del conjunto de datos en conjuntos de entrenamiento y prueba. Una divisi√≥n com√∫n es 70% para entrenamiento y 30% para prueba, pero puedes elegir diferentes proporciones seg√∫n tus necesidades.

![Fuente: https://blogs.sas.com/content/subconsciousmusings/](_resources/images/randomsampling.png){.img-center}

Usa el widget **Data Sampler** para crear una partici√≥n aleatoria del conjunto de datos. Establece el tipo de muestreo en "Random" y elige una proporci√≥n para el conjunto de entrenamiento (por ejemplo, 70% para entrenamiento y 30% para prueba). Conecta la salida del **Data Sampler** a dos widgets **Data Table** para visualizar ambos conjuntos. Debes asegurarte de que la entrada de cada tabla sea la salida correspondiente del **Data Sampler** (una contiene el subconjunto de entrenamiento y la otra el de prueba).

Visualiza c√≥mo se distribuyen dos caracter√≠sticas relevantes en ambos subconjuntos. Puedes usar el widget **Scatter Plot** para visualizar la relaci√≥n entre dos caracter√≠sticas num√©ricas y el widget **Distributions** para ver c√≥mo se distribuyen las caracter√≠sticas individuales. Compara las distribuciones en los conjuntos de entrenamiento y prueba para ver si son similares.

Luego repite el proceso con 95% para entrenamiento y 5% para prueba.

::: {.question-card}
üìù **Preguntas:**   

1. ¬øQu√© proporci√≥n elegiste para los conjuntos de entrenamiento y prueba? ¬øPor qu√©? Cambia la proporci√≥n y observa c√≥mo afecta las distribuciones.
2. ¬øLas distribuciones de las caracter√≠sticas clave se ven similares en ambos subconjuntos? Si no, ¬øqu√© diferencias observaste?
3. ¬øPor qu√© es importante tener distribuciones similares en los conjuntos de entrenamiento y prueba?
4. ¬øC√≥mo afecta el cambio de la proporci√≥n de la divisi√≥n (por ejemplo, 70/30 vs. 95/5) a las distribuciones en los conjuntos de entrenamiento y prueba?
:::

<!-- Soluci√≥n

1. Una elecci√≥n com√∫n es 70% para entrenamiento y 30% para prueba, ya que proporciona un buen equilibrio entre tener suficientes datos para entrenar el modelo y suficientes para evaluar su rendimiento. Cambiar la proporci√≥n puede afectar las distribuciones; por ejemplo, un conjunto de prueba muy peque√±o puede no representar bien el conjunto de datos general. Sin embargo, la elecci√≥n puede depender del conjunto de datos y el problema espec√≠fico.
2. Las distribuciones deber√≠an ser similares idealmente, pero puede haber algunas diferencias debido a la aleatoriedad del muestreo. Si se observan diferencias significativas, podr√≠a indicar que el muestreo aleatorio no captur√≥ bien la distribuci√≥n general de los datos.
3. Las distribuciones similares son importantes para asegurar que el modelo se eval√∫e con datos representativos de lo que fue entrenado. Si el conjunto de prueba tiene una distribuci√≥n diferente, el rendimiento del modelo puede no reflejar con precisi√≥n su capacidad de generalizaci√≥n.
 -->

### 2.2 Particiones estratificadas

En algunos casos, especialmente cuando se trabaja con conjuntos de datos desbalanceados (donde una clase es mucho m√°s com√∫n que otra), el muestreo aleatorio podr√≠a no preservar la distribuci√≥n de clases en ambos subconjuntos. Esto puede llevar a resultados enga√±osos al evaluar el modelo. Para solucionar esto, podemos usar el muestreo estratificado, que asegura que las proporciones de clase se mantengan en los conjuntos de entrenamiento y prueba.

![Fuente: https://blogs.sas.com/content/subconsciousmusings/](_resources/images/stratifiedsampling.png){.img-center}

Usa nuevamente el widget **Data Sampler**, pero esta vez establece el tipo de muestreo en "Stratified". Elige la variable objetivo (la que indica la presencia o ausencia de CKD) para asegurar que ambos subconjuntos mantengan la misma distribuci√≥n de clases que el conjunto original. Luego repite el proceso de visualizar las distribuciones de las caracter√≠sticas clave en ambos subconjuntos usando el widget **Scatter Plot**.

::: {.question-card}
üìù **Preguntas:**

1. ¬øEn qu√© se diferencia el muestreo estratificado del muestreo aleatorio en cuanto a la distribuci√≥n de clases?
2. ¬øNotaste alguna diferencia en las distribuciones de las caracter√≠sticas clave entre los conjuntos de entrenamiento y prueba al usar muestreo estratificado?
3. ¬øPor qu√© es especialmente importante el muestreo estratificado en conjuntos de datos desbalanceados?
:::

<!-- Soluci√≥n

1. El muestreo estratificado asegura que las proporciones de clase se mantengan en los conjuntos de entrenamiento y prueba, mientras que el muestreo aleatorio puede no preservar estas proporciones, especialmente en conjuntos desbalanceados.
2. Al usar muestreo estratificado, las distribuciones de las caracter√≠sticas clave en ambos subconjuntos deber√≠an ser m√°s similares en comparaci√≥n con el muestreo aleatorio, especialmente para la variable objetivo.
3. El muestreo estratificado es importante en conjuntos desbalanceados porque evita que una clase est√© subrepresentada en alguno de los conjuntos, lo que podr√≠a llevar a un rendimiento sesgado del modelo y resultados de evaluaci√≥n poco fiables.
 -->

### 2.3 Validaci√≥n cruzada

Adem√°s de crear una sola divisi√≥n de entrenamiento y prueba, otro enfoque com√∫n para evaluar modelos de aprendizaje autom√°tico es la validaci√≥n cruzada. Esta t√©cnica consiste en dividir el conjunto de datos en m√∫ltiples subconjuntos (o "folds") y entrenar/probar el modelo varias veces, cada vez usando un fold diferente como conjunto de prueba y los restantes como conjunto de entrenamiento. Esto ayuda a asegurar que el rendimiento del modelo sea robusto y no dependa de una divisi√≥n particular de los datos.

![](_resources/images/Cross%20validation.png){.img-center}

Implementaremos la validaci√≥n cruzada en la pr√≥xima sesi√≥n de laboratorio cuando empecemos a construir y evaluar modelos. Por ahora, solo entiende que es una t√©cnica poderosa para evaluar el rendimiento de los modelos de manera m√°s fiable.

### 2.4 Conjunto de validaci√≥n

![](_resources/images/validation.gif){.img-right}

Adem√°s de los conjuntos de entrenamiento y prueba, a menudo es √∫til crear un tercer subconjunto llamado conjunto de validaci√≥n. Este conjunto se utiliza durante el desarrollo del modelo para ajustar hiperpar√°metros y tomar decisiones sobre la arquitectura del modelo sin tocar el conjunto de prueba. El conjunto de validaci√≥n ayuda a evitar el sobreajuste al conjunto de entrenamiento y proporciona una evaluaci√≥n imparcial del modelo durante el desarrollo.

Implementaremos el conjunto de validaci√≥n en la pr√≥xima sesi√≥n de laboratorio. Por ahora, solo comprende su prop√≥sito e importancia.

---

## 3. Normalizaci√≥n de datos

::: {.objective-card}
üéØ **Objetivo:** Comprender la importancia de normalizar los datos.
:::

Cuando se trabaja con conjuntos de datos que contienen caracter√≠sticas num√©ricas en diferentes escalas, es importante normalizar los datos. La normalizaci√≥n asegura que todas las caracter√≠sticas contribuyan por igual a los c√°lculos de distancia utilizados por muchos algoritmos de aprendizaje autom√°tico. Si una caracter√≠stica tiene un rango mucho mayor que otras, puede dominar la m√©trica de distancia y llevar a resultados sesgados. Por ejemplo, si una caracter√≠stica var√≠a de 0 a 1 y otra de 0 a 1000, la segunda tendr√° un impacto mucho mayor en los c√°lculos de distancia.

### 3.1 Normalizaci√≥n Min-Max

La normalizaci√≥n Min-Max es una t√©cnica com√∫n para escalar caracter√≠sticas a un rango espec√≠fico, normalmente [0, 1]. La f√≥rmula es:

$$
X' = \frac{X - X_{min}}{X_{max} - X_{min}}
$$

donde:

- $X$ es el valor original,
- $X_{min}$ es el valor m√≠nimo de la caracter√≠stica,
- $X_{max}$ es el valor m√°ximo de la caracter√≠stica,
- $X'$ es el valor normalizado.

Pasa tus datos al widget **Continuize** y conecta la salida a un widget **Distributions** para visualizar el efecto de la normalizaci√≥n en las caracter√≠sticas. Visualiza c√≥mo se distribuyen dos caracter√≠sticas relevantes antes y despu√©s de aplicar la normalizaci√≥n Min-Max.

::: {.question-card}
üìù **Preguntas:**

1. ¬øCu√°les son las ventajas de usar la normalizaci√≥n Min-Max?
2. ¬øHay posibles inconvenientes al usar la normalizaci√≥n Min-Max?
3. ¬øC√≥mo cambiaron las distribuciones de las caracter√≠sticas tras aplicar la normalizaci√≥n Min-Max?
:::

<!-- Soluci√≥n
1. La normalizaci√≥n Min-Max escala las caracter√≠sticas a un rango espec√≠fico, lo que puede mejorar el rendimiento de algoritmos que dependen de c√°lculos de distancia. Tambi√©n preserva las relaciones entre los puntos de datos originales.
2. Un posible inconveniente es que la normalizaci√≥n Min-Max es sensible a los valores at√≠picos. Si el conjunto de datos contiene valores extremos, pueden afectar significativamente la escala de los dem√°s puntos.
3. Tras aplicar la normalizaci√≥n Min-Max, las distribuciones de las caracter√≠sticas deber√≠an estar escaladas al rango [0, 1]. La forma de las distribuciones puede permanecer similar, pero los valores se ajustar√°n al rango especificado.
-->

### 3.2 Estandarizaci√≥n

La estandarizaci√≥n (tambi√©n conocida como normalizaci√≥n Z-score) es otra t√©cnica com√∫n para escalar caracter√≠sticas. Transforma los datos para que tengan media 0 y desviaci√≥n est√°ndar 1. La f√≥rmula es:

$$
X' = \frac{X - \mu}{\sigma}
$$

donde:

- $X$ es el valor original,
- $\mu$ es la media de la caracter√≠stica,
- $\sigma$ es la desviaci√≥n est√°ndar de la caracter√≠stica,
- $X'$ es el valor normalizado.

Cambia el widget **Continuize** a "Standardization" y conecta la salida a un widget **Distributions** para visualizar el efecto de la estandarizaci√≥n en las caracter√≠sticas. Visualiza c√≥mo se distribuyen dos caracter√≠sticas relevantes antes y despu√©s de aplicar la estandarizaci√≥n.

::: {.question-card}
üìù **Preguntas:**

1. ¬øCu√°les son las ventajas de usar la estandarizaci√≥n?
2. ¬øHay posibles inconvenientes al usar la estandarizaci√≥n?
3. ¬øC√≥mo cambiaron las distribuciones de las caracter√≠sticas tras aplicar la estandarizaci√≥n?
:::

<!-- Soluci√≥n
1. La estandarizaci√≥n transforma las caracter√≠sticas para que tengan media 0 y desviaci√≥n est√°ndar 1, lo que puede mejorar el rendimiento de algoritmos que asumen datos distribuidos normalmente. Es menos sensible a los valores at√≠picos que la normalizaci√≥n Min-Max.
2. Un posible inconveniente es que la estandarizaci√≥n asume que los datos est√°n distribuidos normalmente. Si los datos est√°n muy sesgados, este m√©todo puede no ser apropiado.
3. Tras aplicar la estandarizaci√≥n, las distribuciones de las caracter√≠sticas deber√≠an estar centradas en 0 con desviaci√≥n est√°ndar 1. La forma de las distribuciones puede permanecer similar, pero los valores se ajustar√°n a la escala estandarizada.
-->

### 3.3 Efectos de los valores at√≠picos en la normalizaci√≥n

![](_resources/images/bloodpressure.jpeg){.img-right}

Los valores at√≠picos son valores extremos que difieren significativamente de otras observaciones en el conjunto de datos. Pueden surgir por errores de medici√≥n, errores de entrada de datos o verdadera variabilidad en los datos. Los valores at√≠picos pueden tener un impacto significativo en las t√©cnicas de normalizaci√≥n, especialmente en la normalizaci√≥n Min-Max, ya que pueden distorsionar la escala de los dem√°s puntos.

Observa la variable `bp` (presi√≥n arterial) en el conjunto de datos. Usa el widget **Scatter Plot** y/o **Box Plot** para visualizar la distribuci√≥n de esta variable e identificar posibles valores at√≠picos. Luego, aplica tanto la normalizaci√≥n Min-Max como la estandarizaci√≥n al conjunto de datos usando el widget **Continuize** y visualiza c√≥mo cambian las distribuciones de la variable `bp` tras la normalizaci√≥n.

::: {.question-card}
üìù **Preguntas:**

1. ¬øC√≥mo afectan los valores at√≠picos a la normalizaci√≥n Min-Max?
2. ¬øC√≥mo afectan los valores at√≠picos a la estandarizaci√≥n?
:::

<!-- Soluci√≥n
1. Los valores at√≠picos pueden afectar significativamente la normalizaci√≥n Min-Max al ampliar el rango de la caracter√≠stica, lo que puede hacer que los dem√°s puntos se compriman en un rango m√°s peque√±o.
2. Los valores at√≠picos tambi√©n pueden afectar la estandarizaci√≥n al aumentar la desviaci√≥n est√°ndar, lo que puede hacer que los dem√°s puntos se reduzcan.
-->

### 3.4 Normalizaci√≥n y particiones de datos

Es crucial aplicar las t√©cnicas de normalizaci√≥n solo al conjunto de entrenamiento y luego usar los mismos par√°metros (por ejemplo, m√≠nimo, m√°ximo, media, desviaci√≥n est√°ndar) para transformar el conjunto de prueba. Esto previene el data leakage, que ocurre cuando informaci√≥n del conjunto de prueba se usa durante el entrenamiento, lo que lleva a estimaciones de rendimiento demasiado optimistas.

Para lograr esto en Orange, puedes usar el widget **Apply Domain** para ajustar los par√°metros de normalizaci√≥n en el conjunto de entrenamiento y luego aplicarlos al conjunto de prueba. Para hacerlo, conecta la salida del **Data Sampler** (conjunto de entrenamiento) al widget **Continuize**, y luego conecta la salida del widget **Continuize** al widget **Apply Domain** y config√∫ralo como `Template Data`. Finalmente, conecta la salida del conjunto de prueba del **Data Sampler** al widget **Apply Domain** y config√∫ralo como `Data`. As√≠, los par√°metros de normalizaci√≥n se aprenden del conjunto de entrenamiento y se aplican al conjunto de prueba.

::: {.question-card}
üìù **Preguntas:**

1. ¬øPor qu√© es importante aplicar las t√©cnicas de normalizaci√≥n solo al conjunto de entrenamiento?
2. ¬øQu√© podr√≠a pasar si usamos el conjunto de prueba para ajustar los par√°metros de normalizaci√≥n?
3. ¬øC√≥mo funciona el widget **Apply Domain** en Orange para la normalizaci√≥n?
:::

<!-- Soluci√≥n
1. Es importante aplicar las t√©cnicas de normalizaci√≥n solo al conjunto de entrenamiento para evitar el data leakage, que puede llevar a estimaciones de rendimiento demasiado optimistas.
2. Si usamos el conjunto de prueba para ajustar los par√°metros de normalizaci√≥n, podr√≠amos introducir informaci√≥n del conjunto de prueba en el proceso de entrenamiento, lo que lleva a resultados sesgados y una evaluaci√≥n inexacta del rendimiento del modelo.
3. El widget **Apply Domain** en Orange permite ajustar los par√°metros de normalizaci√≥n en el conjunto de entrenamiento y luego aplicarlos al conjunto de prueba, asegurando que el conjunto de prueba se transforme usando los mismos par√°metros aprendidos de los datos de entrenamiento.
-->

::: {.final-note-card}
La elecci√≥n entre t√©cnicas de normalizaci√≥n como Min-Max y estandarizaci√≥n depende de las caracter√≠sticas espec√≠ficas del conjunto de datos y de los requisitos del algoritmo de aprendizaje autom√°tico que se utilice. La normalizaci√≥n Min-Max suele preferirse cuando los datos est√°n distribuidos uniformemente y el algoritmo requiere un rango espec√≠fico (por ejemplo, [0, 1]). La estandarizaci√≥n es m√°s adecuada para algoritmos que asumen datos distribuidos normalmente o cuando los datos contienen valores at√≠picos.

En la pr√°ctica, es esencial visualizar la distribuci√≥n de los datos antes y despu√©s de aplicar t√©cnicas de normalizaci√≥n. Esto ayuda a identificar el m√©todo m√°s apropiado y a asegurar que los datos transformados cumplen con los supuestos del algoritmo de aprendizaje autom√°tico elegido.
:::

---

## 4. Imputaci√≥n de datos

::: {.objective-card}
üéØ **Objetivo:** Aprender a rellenar valores faltantes en el conjunto de datos.
:::

![](_resources/images/missing.jpg){.img-right}

Los valores faltantes son un problema com√∫n en conjuntos de datos reales. Pueden ocurrir por diversas razones, como errores de entrada de datos, fallos de equipos o encuestados que omiten preguntas en cuestionarios. Tratar los valores faltantes es crucial porque pueden llevar a resultados sesgados y reducir la efectividad de los modelos de aprendizaje autom√°tico. Hay varias estrategias para tratar los valores faltantes, incluyendo:

- **Eliminar filas o columnas** con valores faltantes (si la cantidad de datos faltantes es peque√±a).
- **Imputar valores faltantes** usando medidas estad√≠sticas (media, mediana, moda) o t√©cnicas m√°s avanzadas (por ejemplo, k vecinos m√°s cercanos, regresi√≥n).

La elecci√≥n del m√©todo depende de la naturaleza de los datos y del grado de valores faltantes.

### 4.1 Eliminaci√≥n de valores faltantes

Primero, veamos c√≥mo eliminar filas con valores faltantes. Usa el widget **Impute** para filtrar las filas que contienen cualquier valor faltante. Conecta la salida a un widget **Data Table** para visualizar el conjunto de datos limpio.

::: {.question-card}
üìù **Preguntas:**
1. ¬øCu√°ntas filas se eliminaron debido a valores faltantes?
2. ¬øCu√°les son los posibles inconvenientes de eliminar filas con valores faltantes?
:::

<!-- Soluci√≥n
1. El n√∫mero de filas eliminadas depender√° del conjunto de datos espec√≠fico. Puedes comprobar el n√∫mero de filas antes y despu√©s de aplicar el filtro para determinar cu√°ntas se eliminaron.
2. Eliminar filas con valores faltantes puede llevar a la p√©rdida de informaci√≥n valiosa, especialmente si una parte significativa del conjunto de datos contiene valores faltantes. Tambi√©n puede introducir sesgo si la falta de datos no es aleatoria (por ejemplo, si ciertos grupos tienen m√°s probabilidad de tener datos faltantes).
-->

### 4.2 Imputaci√≥n de valores faltantes

En muchos casos, puede ser m√°s apropiado imputar los valores faltantes en vez de eliminarlos. La imputaci√≥n consiste en rellenar los valores faltantes con estimaciones basadas en los datos disponibles. Hay varios m√©todos para imputar valores faltantes, incluyendo:

- **Imputaci√≥n por media/mediana/moda:** Reemplazar los valores faltantes por la media, mediana o moda de la columna.
- **Imputaci√≥n por k vecinos m√°s cercanos (KNN):** Usar los valores de los vecinos m√°s cercanos para estimar los valores faltantes.
- **Imputaci√≥n por regresi√≥n:** Usar modelos de regresi√≥n para predecir y rellenar los valores faltantes en funci√≥n de otras caracter√≠sticas.

Usa el widget **Impute** para rellenar los valores faltantes. Puedes elegir diferentes m√©todos de imputaci√≥n para diferentes columnas. Conecta la salida a un widget **Data Table** para visualizar el conjunto de datos imputado.

::: {.question-card}
üìù **Preguntas:**

1. ¬øCu√°les son las ventajas y desventajas de usar m√©todos de imputaci√≥n para tratar valores faltantes?
2. ¬øC√≥mo puedes evaluar el impacto de la imputaci√≥n en el conjunto de datos?
3. ¬øEn qu√© situaciones preferir√≠as usar imputaci√≥n en vez de simplemente eliminar los valores faltantes?
:::

<!-- Soluci√≥n
1. Las ventajas de la imputaci√≥n incluyen preservar el tama√±o del conjunto de datos y retener informaci√≥n valiosa. Las desventajas incluyen la posible introducci√≥n de sesgo si el m√©todo de imputaci√≥n no refleja con precisi√≥n la distribuci√≥n subyacente de los datos.
2. Puedes evaluar el impacto de la imputaci√≥n comparando las distribuciones de los conjuntos de datos original e imputado, as√≠ como evaluando el rendimiento de los modelos de aprendizaje autom√°tico entrenados con ambos conjuntos.
3. La imputaci√≥n se prefiere cuando la cantidad de datos faltantes es significativa y eliminar filas llevar√≠a a una p√©rdida sustancial de informaci√≥n. Tambi√©n es √∫til cuando la falta de datos no es aleatoria y eliminar filas podr√≠a introducir sesgo.
-->

---

# Mini-proyecto: Preparando datos para el modelado

En este mini-proyecto, aplicar√°s los conceptos aprendidos en esta sesi√≥n para preprocesar un nuevo conjunto de datos.

![](_resources/images/car.jpg){.img-right}

Imagina que acabas de unirte a un grupo de investigaci√≥n que estudia la calidad de los autom√≥viles y los precios de mercado. El equipo ha recopilado el conjunto de datos **Imports 1985** (disponible en el widget **Datasets**). La primera impresi√≥n puede ser que es rico y detallado. Sin embargo, una mirada m√°s cercana revela varios problemas: algunos atributos contienen valores faltantes o inconsistentes (a menudo codificados como `?`), otros est√°n medidos en escalas muy diferentes, y hay algunos casos extremos que podr√≠an ser verdaderos valores at√≠picos del mercado o simples errores de registro. Adem√°s, algunas columnas num√©ricas pueden estar almacenadas como texto y no ser reconocidas correctamente como num√©ricas, y no todos los atributos disponibles son necesariamente relevantes para la tarea de predicci√≥n.

Tu papel es dise√±ar un flujo de trabajo de preprocesamiento en Orange que transforme este conjunto de datos en uno confiable y listo para el modelado (por ejemplo, para predecir el `price` o construir un clasificador para `symboling`). Esto requerir√° tomar decisiones sobre qu√© variables conservar, c√≥mo tratar los datos incompletos, si ajustar o no las escalas de las variables y qu√© hacer con los valores inusuales. Una vez que hayas llegado a una versi√≥n del conjunto de datos que consideres adecuada, deber√°s asegurarte de que est√© correctamente dividido en subconjuntos de entrenamiento y prueba para que los modelos futuros puedan evaluarse de manera justa.

No existe una √∫nica secuencia de pasos correcta, y diferentes elecciones pueden llevar a resultados distintos. Lo importante es que pienses cuidadosamente en cada decisi√≥n y puedas justificar por qu√© trataste los datos de la manera en que lo hiciste. Al final, guarda tu flujo de trabajo y escribe una breve reflexi√≥n describiendo tu razonamiento: explica qu√© pasos aplicaste, cu√°les decidiste que no eran necesarios y qu√© tan seguro est√°s de que el conjunto de datos ahora est√° listo para usarse en las siguientes sesiones de laboratorio.

# Nota final

::: {.final-note-card}
‚ú® ¬°Excelente trabajo! Has aprendido a preprocesar datos de manera efectiva, lo cual es un paso crucial en cualquier proyecto de aprendizaje autom√°tico. Al limpiar los datos, tratar los valores faltantes, normalizar las caracter√≠sticas y crear particiones adecuadas, has sentado una base s√≥lida para construir modelos confiables.

En la pr√≥xima sesi√≥n, ver√°s c√≥mo estas decisiones impactan el rendimiento de los modelos de aprendizaje supervisado. Recuerda guardar ambos flujos de trabajo (el original y el preprocesado) para que puedas comparar sus efectos.
:::

::: {.margin}
# Explora los Laboratorios {.unnumbered .unlisted}
{{< include lab-cards.qmd >}}
:::